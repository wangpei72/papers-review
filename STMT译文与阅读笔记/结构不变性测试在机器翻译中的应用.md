# 结构不变性测试在机器翻译中的应用

## 摘要

近年来，机器翻译软件已越来越多地融入到我们的日常生活中。人们通常将机器翻译用于各种应用程序，例如向外国医生描述症状并用外语阅读政治新闻。但是，支持现代机器翻译的神经机器翻译（NMT）模型的复杂性和难处理性使得这些系统的鲁棒性甚至难以做出评估，无论保证。机器翻译系统可能返回的结果不佳，从而导致错误理解，进而导致例如医疗误诊，人身安全威胁或政治冲突等案例。尽管它具有明显的重要性，验证机器翻译系统的鲁棒性仍然非常困难，因此尚未得到充分的研究。

为了应对这一挑战，我们引入了结构不变性测试（SIT），一种用于验证机器翻译软件的新颖测试方法。我们的主要见解是，“相似”源句的翻译结果通常应呈现出相似的句子结构。具体而言，SIT

1. 通过将给定句子中的一个单词替换为语义上相似，句法上等效的单词来生成相似的源句子；
2.  通过语法分析树（通过选区或依赖性分析获得）表示句子结构； 
3. 报告句子结构在数量上相差超过某个阈值的句子对。

为了评估SIT，我们使用它来测试谷歌翻译和必应微软翻译。通过输入200个源句子，共获得64个和70个错误问题，其最高准确性分别为69.5％和70％。翻译错误多种多样，包括翻译不足，翻译过度，修改不正确，词/短语误译和逻辑不清晰。

## 关键词

变形测试，机器翻译，结构不变性

## 简介

在过去的十年中，机器翻译软件得到了快速的发展。 用户现在依靠机器翻译来实现各种用途，例如在国外学习时签署租赁协议，向外国医生描述症状以及用外语阅读政治新闻。 2016年，使用最广泛的在线翻译服务Google Translate吸引了超过5亿用户，每天翻译超过1000亿个单词[81]。 最重要的是，机器翻译服务也被嵌入到各种软件应用程序中，例如Facebook [25]和Twitter[82]。

机器翻译的进步在很大程度上可以归因于神经机器翻译（NMT）模型，该模型已成为许多机器翻译系统的核心组件。正如Google [86]和Microsoft [32]的研究报告所指出的那样，最新的NMT模型在准确性上正在逼近人类翻译的水准，这些最近的突破使用户在日常生活中开始依赖机器翻译软件（例如Google Translate [30]和Bing Microsoft Translator [5]）。

但是，NMT模型并不像许多人所认为的那样可靠。
最近，在以神经网络为核心组件的各种软件系统中发现了次优和错误的输出。 典型示例包括自动驾驶汽车[23、68、79]，情感分析工具[2、36、46]和语音识别服务[6、71]。这些最新的研究工作表明，在经过特殊设计的输入（例如对抗示例）的情况下，神经网络可以轻易地返回劣等结果（例如错误的类别标签）。 NMT模型也不例外。 它们可能会被对抗性示例[22]或自然噪音（例如输入句子中的错字）[4]所欺骗。 这些较差的结果（即翻译效果不佳或翻译不正确）可能会导致误解，尴尬，财务损失，医疗误诊，人身安全威胁或政治冲突[17，57，64，65，80]。因此，确保机器翻译软件的健壮性是一项重要的工作。

然而，测试机器翻译软件极具挑战性。首先，机器翻译软件与传统的逻辑以源代码编码的软件不同，它基于具有数百万个参数的复杂神经网络。因此，大多数基于代码的传统软件的测试技术无效。其次，最近对测试人工智能（AI）软件进行的研究[2，29，36，37，46，62，68]集中于具有更简单输出格式的任务，例如测试图像分类器，给定图像的输出类标签。但是，作为最困难的自然语言处理（NLP）任务之一，机器翻译系统（即翻译的句子）的输出要复杂得多。由于AI测试的结构并不适合处理此类复杂的输出，因此当将它们应用于NMT模型时，典型的AI测试方法几乎只能找到“非法”输入，例如带有语法错误的语句或不太可能作为输入的明显拼写错误。但是这些错误在实践中并不是有问题的。如WeChat（一个月活跃用户超过10亿的Messenger应用）所报道的那样，即使输入句子在语法上是正确的，其嵌入的NMT模型也可能返回较差的结果[96]。由于难以建立有效，自动化的方法来评估翻译的正确性，因此目前用于测试机器翻译软件的方法存在许多缺陷。



解决上述问题的方法自身仍然具有缺陷，即无法检测语法错误和缺乏实际测试用例。当前机器翻译软件的测试程序通常包括三个步骤[96]：（1）收集双语句子对并将其分成训练，验证和测试数据； （2）根据测试数据计算经过训练的NMT模型的翻译质量得分（例如，==BLEU== [67]和==ROUGE== [48]）； （3）将分数与预定义的阈值进行比较，以确定测试案例是否通过。但是，基于阈值得分（如BLEU）的测试很容易忽略语法错误，这是由于该阈值得分是对目标和参考之间的重叠程度进行的度量。另外，翻译质量分数（例如，BLEU）的计算需要双语句子对作为输入，这需要预先手动构建。要在训练集之外使用真实世界的用户输入进行测试，需要对真实翻译进行大量的手动操作。因此，迫切需要一种能够自动检测机器翻译软件中的错误，有效且高效的测试方法。

为了解决上述问题，我们引入结构不变式测试（SIT），这是一种新颖的，可广泛应用的验证机器翻译软件的方法。==关键见解是类似的源句，例如相差一个单词的句子-通常具有相似的句子结构翻译结果。==例如，图1显示了三个相似的英语原文句子和它们的中文目标句子。前两个翻译是正确的，而第三个则不正确。我们可以看到，中文第三句的结构与其他两个句子明显不同。对于每个源句子，SIT

1. 通过使用自然语言处理技术（即BERT [19]）修改源句子中的单个单词来生成其相似句子的列表。
2. 将所有句子提供给被测软件以获取其翻译； 
3. 使用专门的数据结构（即选区分析树和依赖关系分析树）来表示每个翻译句的语法结构； 
4. 比较翻译句子的结构。如果翻译后的原语和任何翻译后的修饰语的结构之间存在较大差异，我们会将修饰语对与原始句子对一起报告为潜在错误。

我们使用SIT来测试Google Translate和Bing Microsoft Translator，并从网络中检索200个源句子作为输入。 SIT成功地在Google Translate中找到了64个错误问题（在第3节中定义），在Bing Microsoft Translator中成功找到了70个错误问题（最高准确度分别为69.5％和70％）。 报告的错误多种多样，包括翻译不足，翻译过度，修改不正确，词/短语错误翻译和逻辑不清晰，而广泛使用的指标BLEU和ROUGE均无法检测到这些错误。 图2中显示了不同

翻译错误的示例。源代码和数据集也已发布以供重用。请注意，我们的结果仅仅涉及到谷歌翻译和必应微软翻译在我们做测试时的快照，在2019年我们发布我们的结果数据集之后，我们发现所报告的一些问题已经得到了解决。

该论文主要做出以下方面的贡献：

- 它介绍了结构不变测试（SIT），这是一种新颖的，可广泛应用的验证机器翻译软件的方法。
- 通过调整BERT [19]生成相似的句子并利用语法分析器表示句子结构，描述了SIT的实际实现。
- 它仅使用从Web爬取的200个源句来呈现SIT的评估，从而成功地在Google Translate中成功发现了64个有问题的bug，并在Bing Microsoft Translator中成功找到了70个有问题的bug
- 讨论了SIT发现的各种错误类别，而最新的度量标准都找不到。

## 真实案例

汤姆计划将他14岁的儿子大卫带到苏黎世动物园。 在参观动物园之前，他检查了动物园网站4上有关购票的内容，并看到以下德语句子：

==Kinder bis 15 Jahre erhalten an ihrem Geburtstag gegen Vorweisen eines gültigen Ausweises den Zooeintritt geschenkt.==

汤姆来自美国，他不懂德语。 为了弄清其含义，汤姆使用了Google Translate，这是一种由NMT模型提供支持的流行翻译服务[86]。 Google翻译返回了以下英语句子：

==Children up to the age of 15 are given free admission to the zoo on presentation of a valid ID==

但是，即使拥有有效身份证件，动物园工作人员也拒绝了戴维免费进入。 他们发现他们误解了动物园的规定，原因是Google翻译返回的翻译不正确。 正确的翻译应该是:

==Children up to the age of 15 are given free admission to the zoo **on their birthday** on presentation of a valid ID.==

这是真正的翻译错误，导致令人困惑，不愉快经验。 翻译错误也可能导致非常严重的后果[17，57，65，80]。 例如，一名巴勒斯坦男子因一则帖子说“早上好”而被以色列警察逮捕，Facebook的机器翻译服务错误地将其翻译为希伯来语为“攻击他们”，而英语为“伤害他们” [17，65]。 这既表明了对机器翻译软件的广泛依赖，也证明了当软件出现故障时可能产生的负面影响。为了提高机器翻译软件的可靠性，本文介绍了一种称为结构不变测试的通用验证方法，该方法可以自动准确地检测出未能被预测出的潜在翻译错误。

## 方法实现



本节介绍结构不变测试（SIT），并描述我们的实现。 SIT的输入是未标记的单语句子列表，而SIT的输出是可疑问题列表。  对于每个原始句子，SIT会报告0（即未找到错误）或1个问题（即至少找到1个有错误句子）。每个问题中包括（1）原始句子及其翻译句子（2）原始句子和生成的修饰句子距离指标相距最远的k个修饰后原始句子及其翻译。报告原始句子对的原因如下：（1）了解原始句子的修改方式可以帮助用户理解翻译系统为什么会犯错误；（2）错误实际上可能在于原始句子的翻译。

图3概述了SIT。 在此图中，我们为了简化和清楚起见，使用一个原始句子作为输入。 SIT的关键见解是，相似的源语句的目标语句通常具有相似的句法结构。 从这种见解得出来，SIT执行以下四个步骤：

1. 产生相似的句子。 对于每个源句子，我们通过修改句子中的单个单词来生成其相似句子的列表；
2. 收集目标句子。 我们将原始的和生成的类似句子提供给被测机器翻译系统，并收集它们的目标句子；
3. 表示目标句子结构。 所有目标词都被编码为专门用于自然语言处理的数据结构；
4. 检测翻译错误。 将翻译后的修饰句子的结构与翻译后的原始句子的结构进行比较。 如果结构之间存在较大差异，则SIT报告潜在错误。

### 生成相似句子

为了测试结构不变性，我们必须比较两个句法结构相同但在至少一个记号上不同的句子。 我们发现，对于给定的输入句子，在一定的约束下一次更改一个句子中的一个单词有效地产生了一组结构相同且语义相似的句子。

明确地说，我们采用的方法是修改输入句子中的单个标记，将其替换为相同词性的另一个标记，以产生一个替代句子。 例如，我们将在图4的源句子中，屏蔽“ hairy”，并用前k个最相似的标记替换它，以生成k个相似的句子。 我们针对句子中的每个候选标记执行此操作，为了简单起见并避免语法上奇怪或不正确的句子，我们仅使用名词和形容词作为候选标记。

现在我们讨论选择替换标记的问题。选择一组替换标记的最简单算法也许包括使用单词嵌入[60]。可以选择与原始句子中给定标记具有高矢量相似度且具有相同POS标签的单词，作为修改句子中的替换词。  但是，由于单词嵌入无论上下文如何都具有相同的值，因此这种方法通常会产生普通语言不会出现的感觉。例如，单词“fork”可能与单词“ plate”具有很高的矢量相似度，并且具有与单词“ plate”相同的POS标签。 但是，虽然句子“他来到路边的叉子”挺有感觉，但是句子“他来到路边的盘子”听起来就不大现实。

相反，我们需要一个考虑周围单词并提供一组替换词的模型，这些替换词在插入后可创建真实的句子。受到Cloze任务[78]启发的屏蔽语言模型（MLM）[59]就是做到这一点的模型。MLM的输入是一段带有单个标记的文本（即从句子中删除并用特殊的指示标记代替）。然后，模型的工作是在给定上下文的情况下预测该位置的标记。这种方法迫使模型学习不同标记之间的依赖关系。由于单个单词可以有多种不同的上下文，因此从某种意义上说，此模型允许单个标记具有多种表示形式。因此，我们获得了一组与上下文相关的替换标记。虽然不能保证预测标记具有与原始标记相同的含义，但是如果对MLM进行了很好的训练，则很有可能带有新的预测标记的句子在语法上既正确又有意义。

句子生成过程的一个例子如图4所示。对于我们的实现，==我们使用BERT [19]，这是Google最近提出的一种最新的语言表示模型。 BERT模型提供了预训练的语言表示形式，可以通过添加额外的轻量级softmax分类层来进行微调==，以创建适用于各种与语言有关的任务的模型，例如屏蔽语言建模。  BERT对大量数据进行了训练，这些数据是BooksCorpus（800Mwords）和English Wikipedia（2,500Mwords）的串联，而屏蔽语言任务是用于培训的两个主要任务之一。 因此，在这一方面我们认为BERT非常适合我们的问题。

### 收集目标句

一旦我们从原始句子中生成了类似句子的列表，下一步就是将所有源句子输入到被测试的机器翻译软件中，并收集相应的翻译结果（即目标句子）。 随后，我们分析结果以发现错误。 我们将Google和Bing的机器翻译系统用作实验的测试系统。 为了获得翻译结果，我们调用Google Translate和Bing Microsoft Translator提供的API，它们返回的结果与其Web界面相同[5，30]。

### 表示目标句子

接下来，我们必须对从测试中的翻译系统获得的目标句子建模，因为这使我们能够比较结构以检测错误。 选择用来表示句子的结构将影响我们有效执行比较的能力。 我们最终需要一种能够精确建模句子结构的表示形式，同时提供两个值之间的快速比较。

最简单，最快的方法是比较原始形式的句子：以字符串形式。 确实，我们测试了这种方法并且性能是合理的。 但是，在许多情况下此方法都无法实现。 例如，句子“星期五，我们去看电影”中的介词短语“星期五”也可以放在句子的末尾(中文是中间)，如下所示：“我们星期五去看电影”。 这些句子可以互换，但是诸如字符编辑距离之类的度量将表示字符串之间的差异很大。 语法分析克服了以上问题。 使用语法分析器，我们可以对字符串的句法结构以及单词或单词组之间的关系进行建模。 例如，如果解析正确完成，则我们上面的两个示例语句在关系值和解析结构方面应具有相同的表示形式。

#### 原始目标句子

对于此方法，我们将目标句子保留为其原始格式，即字符串。 在大多数情况下，我们可能希望以一种语言编辑一个句子中的单个标记会导致翻译的句子中的单个标记发生变化。 理想情况下，所有机器翻译系统中变化的替换标记的语法作用是相同的。 但是，实际上并非总是这样，因为介词短语，修饰语和其他成分通常可以被翻译系统放置在不同的位置，并产生语义上等价的，语法正确的句子。 尽管如此，该方法还是一个很好的基准。

#### 选区分析树

选区分析是一种推导字符串的语法结构的方法。它会生成一组选区关系，以显示一个单词或一组单词如何在句子中形成不同的单元。这组关系对SIT尤其有用，因为它将反映句子中短语类型的变化。例如，虽然介词短语可以放置在多个位置以产生具有相同含义的句子，但该组选区关系将保持不变。选区关系可以可视化为一棵树，如图5所示。选区分析树是有序的，有根的树，其中非终端节点是构成关系，终端节点是单词。形式上，在选区分析中，一个句子根据给定的无上下文语法统领的短语结构规则[14]分解成其组成部分。对于我们的实验，我们使用Zhu等人的==shift-reduce==选区解析器。 [99]，并在斯坦福大学的CoreNLP库[31]中实现。它每秒可以解析大约50个句子。

#### 依赖关系分析树

依赖解析同样得出了字符串的句法结构。 但是，产生的一组关系描述了单词之间的直接关系，而不是单词如何构成句子。 这组关系为我们提供了有关结构的不同见解，并且对于SIT直观上很有用，因为它反映单词之间的变化。 在过去的15年中，依赖项解析已取得了很大的进步。 随着基于神经网络的解析器的引入，它的速度和准确性得到了显着提高[11]。 与==移位减少选区解析器==一样，基于神经网络的依赖解析器使用类似堆栈的系统，在该系统中，使用一个分类器来选择转换。

在这种情况下，分类器是一个神经网络，同样在带标注的树库上进行训练。 对于我们的实现，我们使用由Stanford CoreNLP提供的最新的基于神经网络的解析器，它可以每秒解析约100个句子。 我们使用通用依赖关系库作为我们的标注方案，该方案是基于斯坦福依赖关系库[18]演变而来的。

### 通过结构比较检测翻译错误

最后，为了发现翻译错误，我们通过比较句子表示形式来搜查句子结构上的变化。 不管是将模型建模为原始字符串，词嵌入还是解析树，都有许多不同的度量标准可用于计算两个值之间的距离。 这些指标往往是特定于域的，并且彼此之间的相关性可能很低，这使得指标的选择变得异常重要。 例如，诸如“单词移动器的距离” [41]之类的度量将使我们在两个句子“他去商店”和“将他去商店”之间的距离为0，而字符编辑距离为14。 我们提供了几种不同的度量标准来评估句子之间的距离：字符（Levenshtein）编辑距离，选区集差异和依赖集差异。

#### 原始句子之间的Levenshtein距离

Levenshtein距离[44]（有时更通常称为“编辑距离”）比较两个字符串，并通过计算转换一个字符串所需的最少字符编辑（删除，插入和替换）次数来确定它们之间的匹配程度。 尽管该方法可能无法很好地证明句子之间的句法相似性，但是它利用了一种期望，即用一种语言编辑句子中的单个标记通常会导致翻译后的句子中仅单个标记发生变化。 因此，Levenshtein距离是一个很好的基线指标。

#### 成分分析树之间的关系距离

为了评估两组构成关系之间的距离，我们将两个构成语法列表之间的距离计算为每种短语类型计数的绝对差之和，这使我们对句子在修改后的变化方式有一个基本的了解。这种启发式方法的动机是，单个标记不同的句子的组成部分应在两个词之间保持相同， 在强大的机器翻译系统中，这也应反映在目标句子中。

#### 依赖分析树之间 的关系距离

同样，为了计算两个依赖关系列表之间的距离，我们求和了每种类型的依赖关系的数量的绝对差。 再次，动机是当替换单个标记时，单词之间的关系将理想地保持不变。 因此，集合中的变化是合理的指示，表明违反了结构不变性，并且可能存在翻译错误。

#### 距离阈值化

使用以上指标之一，我们计算原始目标句子与生成的目标句子之间的距离。 然后，我们必须确定修改后的目标句子是否与其相应的原始目标句子相距足够远，以表明存在翻译错误。 为此，我们首先基于距离阈值进行过滤，仅保留距原始句子比所选阈值更远的句子。 然后，对于给定的原始目标句子，我们报告最远的k个修改的目标句子（k也是选择的参数）。 我们将距离阈值保留为手动参数，因为用户可以根据自己的目标优先选择最小化==正向==误报或最小化==负向==误报。 在第4.6节中，我们显示了不同阈值的折衷结果。 对于每个原始句子，如果至少一个生修改后的句子的翻译结果句被认为是有错误的，则将报告问题。

## 评估

在本部分中，我们通过将其应用于Google Translate和Bing Microsoft Translator并通过从网络上爬取的真实世界中未标记的句子来评估我们的方法。 我们的主要研究问题是：

- •RQ1：在机器翻译软件中查找错误翻译的方法有多有效？
- •RQ2：我们的方法会发现哪些翻译错误？ 
- •RQ3：该方法的效率如何？
-  •RQ4：在实践中我们如何选择距离阈值？

### 实验装置

为了验证SIT的结果，我们手动检查了每个已报告的问题，并共同决定：（1）该问题是否包含错误的句子； （2）如果是，它包含什么样的翻译错误。 所有实验均在配备6核心Intel Core i7-8700 3.2GHz处理器，16GB DDR4 2666MHz内存和GeForce GTX 1070 GPU的Linux工作站上运行。 Linux工作站运行带有Linux内核4.25.0的64位Ubuntu 18.04.02。

### 数据集

通常，为了测试机器翻译系统，开发人员可以采用SIT，并将任何源语句作为输入。因此，为了评估我们方法的有效性，我们从Web收集了真实的源句。具体来说，从CNN（有线电视新闻网）的文章中提取输入的句子，分为两类：政治和商业。数据集是从两类文章中收集的，因为我们打算评估SIT是否在不同语义上下文的句子中始终表现良好。对于每个类别，我们都检索了10篇最新文章，摘录自它们的主要文本内容，并将它们分成句子列表。然后，我们从每个句子列表中随机选择100个句子作为实验数据集（总共200个）。在此过程中，包含超过35个单词的句子被过滤掉，因为我们打算证明机器翻译软件即使对于较短的简单句子也可以返回较差的结果。表1中说明了收集的数据集的详细信息。

### SIT的效率

我们的方法旨在使用未标记的句子自动查找翻译错误，并将其报告给开发人员。 因此，该方法的有效性在于两个方面：

- （1）报告的结果有多准确； 
- （2）SIT可以找到多少个错误的句子？ 



在本节中，我们通过使用表1所示的数据集应用SIT来测试Google Translate和Bing Microsoft Translator来评估这两个方面。

#### 评估指标

SIT的输出是一个问题列表，每个问题包含

- （1）原始原文及其翻译； 
- （2）报告的前k个生成的句子及其翻译（即距源句子翻译最远的k个翻译）。 

在这里，我们将top-k准确性定义为报告的问题的百分比，其中，报告的前k个句子或原始句子中至少有一个包含错误。 我们将其用作SIT的准确性指标。 明确地说，如果在问题i的前k个生成的句子中有一个错误的句子，则我们认为该问题报告是准确的，并将buggy（i，k）设置为true； 否则我们将buggy（i，k）设置为false。 如果原始句子有错误，并且被报告为问题，那么我们还将buggy（i，k）设置为true。 给定问题I的列表，其top-k精度计算如下：
$$
Accuracy_k = \frac{\Sigma_{i\in I}buggy(i,k)}{|I|}
$$


#### 结果分析

Top-k精度。 结果总结在表2中。SIT（原始），SIT（组成部分）和SIT（依赖）是分别以原始句子，选区结构和依赖结构作为句子结构表示的SIT实现。 表格中的每一项均显示了前k个准确性以及发现问题的数量。 为简便起见，在随后的讨论中，我们将SIT（构成）和SIT（依赖）分别称为SIT（Con）和SIT（Dep）。

我们观察到SIT（Con）和SIT（Dep）始终比SIT（原始）更好，它证明了句子的结构表示的重要性。 SIT（Raw）中使用的度量标准仅基于句子中的字符，该度量标准很脆弱，并且容易出现误报。例如，SIT（原始）可能报告单词级别上不同但句子结构相似的句子，从而导致误报。 SIT（Con）和SIT（Dep）在top-k准确性和报告的错误问题数量方面均达到可比的性能。特别是，在测试Bing Microsoft Translator时，SIT（Dep）报告100个可疑问题。在这些问题中，有70个在第一个报告的句子或原始句子中包含翻译错误，达到了70％的top-1准确性。对于Google Translate和Bing Microsoft Translator，SIT（Dep）在Top-1准确性上具有最佳性能。它成功地发现了top-1的准确性分别为69.5％和71％的64个和70个错误问题。 SIT（Dep）还实现了最高的top-3准确性（73.9％和78％）。请注意，同一期的原文句子仅相差一个字。因此，与检查前1个句子相比，检查前3个句子不会引起更多的工作。

此外，我们研究了SIT是否会在生成的句子中触发新的错误。如表3所示，在报告的问题中，Google Translate和Bing Microsoft Translator在原始句子的翻译中分别发现了55和60个独特错误。除了这些错误之外，SIT还发现了79和66个额外的唯一错误，这些错误仅在生成的句子对中显示，而在原始句子中则不显示。因此，鉴于其最高的top-k准确性和报告的许多其他独特错误，我们认为SIT在实践中非常有用。

由于以下原因，我们未将SIT的准确性与[96]和[97]进行比较。 SIT针对一般的误译错误，而[96]则针对翻译不足/翻译过度。因此，我们没有进行经验比较。就错误类型和数量而言，[96]只能在原始句子翻译中发现一些翻译不足/过度翻译错误，而SIT则可以找到原始句子及其派生相似句子的翻译中的一般错误。 [97]要求输入句子具有特殊的结构，因此它无法使用我们的数据集检测到任何错误。

### SIT报告的翻译错误

SIT能够发现各种翻译错误。 在我们使用Google Translate和Bing Microsoft Translator进行的实验中，我们主要发现5种翻译错误：翻译不足，翻译过度，修饰不正确，词/短语误译和逻辑不清晰。 错误类型源自用于机器翻译的错误分类方法。 五个错误中的每一个都是词汇，句法或语义错误的子集[34]。 我们以更直观的方式对它们进行重命名以帮助读者。 为了让您一目了然地发现各种错误，本节重点介绍了所有5种错误的示例。 表4列出了发现的SIT翻译错误的统计信息。 SIT发现的大多数翻译错误是翻译不足，词/短语误译和逻辑不清晰的原因。

- 翻译不足。 如果某些单词错误地未翻译（即未出现在翻译中），则可能是翻译错误。 图6给出了包含翻译不足错误的句子对。 在此示例中，“ to Congress”错误地未翻译，从而导致目标句子具有不同的语义。 具体来说，“向国会撒谎”是非法的，而“撒谎”只是不适当的行为。 同样，第2节介绍的真实示例是由翻译不足错误引起的。
- 过度翻译。 如果某些单词不必要地多次翻译，或者目标句子中的某些单词未与源句子中的任何单词进行翻译，则可能是翻译过度。 在图7中，目标句子中的“思想”没有从源句子中的任何单词翻译出来，因此是翻译过度错误。 有趣的是，我们发现过度翻译错误经常与其他一些错误一起发生。 该示例还包含翻译不足错误，因为源句子中的“正确”是错误地未翻译的。 在图2的第二个示例中，单词“ a”被不必要地翻译了两次，这使其成为过度翻译错误。
- 修饰不正确。如果某些修饰语修改了句子中的错误元素，则是不正确的修饰错误。在图8中，修饰语“新”修饰源句中的“汽车制造”。但是，Google Translate认为“新”应修饰“制造中心”。在图2中，第三个示例还显示了一个有趣的错误修改错误。在此示例中（“特权囚犯”），“特权”在源句中修饰了“囚犯”，而Google Translate认为“囚犯”应该修饰了“特权”。我们认为在NMT模型的训练数据中，有一些短语具有类似的模式：“ A of B”，其中A修饰B，在这种情况下会导致错误的修饰错误。有趣的是，触发此错误的原始句子是“但是即使如此，它们仍然是特权的堡垒”。在原始句子中，“堡垒”修饰了“特权”，这与假定的原型相符。如我们所料，这句话已由Google翻译正确翻译。
- 词/短语误译。如果某些标记或短语在目标句子中的翻译不正确，则是单词/短语翻译错误。图9呈现了这种错误的两个主要子类别：（1）多义性的歧义和（2）错误的翻译。
  一词多义的歧义。每个词段/短语可以具有多个正确的翻译。例如，承认（admit）是指“允许某人加入组织”或“不情愿地同意某件事”。但是，通常在特定的语义上下文（例如，句子）中，标记/短语仅具有一个正确的翻译。现代翻译软件在多义性方面表现不佳。在图9的第一个示例中，Google Translate认为源句中的“承认”是指“不情愿地同意某件事”，从而导致词组误译错误。
  翻译错误。标记/短语也可能被错误地转换为在语义上似乎无关的另一种含义。例如，在图9的第二个示例中，必应Microsoft翻译认为“南”是指“韩国”，从而导致单词/词组误译。
- 逻辑不清楚。 如果所有标记/短语都正确翻译，但句子逻辑不正确，则说明逻辑错误不明确。 在图10中，Google Translate正确翻译了“在当选办公室任职”和“国家”。 但是，由于Google Translate无法理解两者之间的逻辑关系，因此Google Translate生成“在当选国家任职”而不是“担任民选职务的国家”。 NMT模型提供的翻译中普遍存在不清楚的逻辑错误，这在某种程度上表明模型是否真正理解某些语义。
- 复合翻译错误的句子。 报告的句子对中一定百分比包含多个翻译错误。 图11给出了包含三种错误的句子对。 具体而言，“覆盖”是指原文句中的“报道新闻”。 但是，它被翻译为“保留”，从而导致单词/短语翻译错误。 另外，目标句子中的“教会”不是源句子中任何单词的翻译，因此是过度翻译错误。 Bing Microsoft翻译人员还错误地认为该主题是“参加葬礼”。 但是源句实际上意味着主题是“正在葬礼上”，所以这是一个不清楚的逻辑错误。

### SIT运行时间

在本节中，我们评估两个数据集上SIT的运行时间。 我们将SIT应用于3种不同的句子结构表示形式，以测试Google Translate和Bing Microsoft Translator。 我们将每个实验设置运行10次，并报告其平均值作为结果。 SIT的总体运行时间如表5所示，而Google Translate上SIT的每个步骤的运行时间如图12所示（Bing的结果相似）。 我们可以观察到使用原始句子作为结构表示的SIT最快。 这是因为SIT（原始）不需要任何结构表示生成时间。 使用依赖解析器的SIT可获得与SIT（原始）相当的运行时间。 特别是，SIT（Dep）使用19秒来解析2000多个句子（而SIT（Raw）则使用0秒），我们认为这是有效且合理的。

在这些实验中，我们对每个翻译系统执行一次翻译步骤，并在所有实验设置中重复使用翻译结果，因为其他设置对翻译时间没有影响。 因此，在表5中，不同SIT实现的转换时间值相同。 我们可以看到，SIT花费了大部分时间来收集翻译结果。 在此步骤中，对于每个句子，我们都会调用Google和Bing提供的API来收集翻译后的句子。 实际上，如果用户希望使用SIT测试自己的机器翻译软件，则此步骤的运行时间将大大减少。 如最近的一项研究[92]所示，当前的NMT模型可以使用单个NVIDIA GeForce GTX 1080 GPU每秒翻译约20个句子。 利用更强大的计算资源（例如TPU [86]），现代的NMT模型可以达到每秒数百个句子翻译的速度，这比我们的实验快大约2个数量级。

SIT的其他步骤非常高效，如表5和图12所示。SIT（原始）和SIT（Dep）大约花费1分钟，而SIT（Con）大约花费2分钟。 与SIT（Dep）相比，SIT（Con）较慢，因为用于选区解析的模型比用于依赖项解析的模型要慢。 我们得出结论，作为一种离线工作的工具，SIT实际上在测试机器翻译软件方面非常有效。

### 距离阈值的影响

如果翻译的生成句子与原始目标句子之间的距离大于距离阈值，则SIT报告问题中的前k个句子对。 因此，此距离阈值控制着（1）报告的错误问题的数量和（2）SIT的top-k准确性。 凭直觉，如果降低阈值，则会报告更多的问题，而准确性会降低。 图13展示了距离阈值对这两个因素的影响。 在此图中，SIT（Dep）用于在具有不同距离阈值的我们的政治和商业数据集上测试Bing Microsoft Translator。 我们可以观察到，当阈值较小或较大值的中间波动时，报告问题的数量和top-1准确性均保持稳定。 测试Google翻译时，更改距离阈值的影响是相似的。

基于这些结果，我们提出了一些在实践中使用SIT的指导。首先，如果我们打算发现尽可能多的翻译错误，则应使用较小的距离阈值。一个小的阈值（例如，对于依赖项集为4）在我们所有的实验设置中都可以很好地工作。特别是，在阈值较小的情况下，SIT会以正确的准确性（例如70％的top-1准确性）报告最多的问题。我们在4.3.2节的准确性实验中采用了这种策略。当开发人员要在发布之前进行大量测试时，他们可以使用距离阈值较小的SIT。其次，如果我们打算使SIT尽可能准确，则可以使用较大的阈值（例如15）。阈值较大时，SIT可以以极高的准确度（例如86％的top-1准确度）报告较少的问题。鉴于源句子在Web上的数量是无限的，我们可以继续以较大的距离阈值运行SIT并定期报告问题。因此，我们认为SIT是有效的，并且易于在实践中使用。

### 基于SIT报告的错误进行微调

在本节中，我们研究所报告的错误句是否可以作为微调集来提高NMT模型的鲁棒性。 微调是NMT中的一种常见做法，训练数据和目标数据通常可以占据不同的域[15，74]。 具体来说，我们在具有2M双语句子对的CWMT语料库的子集上训练具有全球关注度的编码器-解码器模型[51]-NMT模型的标准体系结构[16]。 编码器和解码器是单向单层LSTM。 我们使用Adam优化器[40]训练模型，并在每个时期后根据保留的验证集计算BLEU [67]分数。 我们将模型与来自验证BLEU得分最高集合片段的参数一起使用。 请注意，我们此处未使用Google或Bing的翻译模型，因为它们不是开源的； 但是，引入注意力机制的编码器-解码器模型是非常有代表性的NMT模型。

为了测试NMT模型，SIT在40个英语句子上运行，这些句子是从WMT'17 [85]的验证集中选择的，方法是删除长句子（即，超过12个单词），并确保所有单词都在NMT模型的词汇表中。请注意，由于未针对该领域的数据对模型进行训练或验证，因此我们模拟了实际情况，其中实际输入与模型训练数据有所不同。根据这些输入，SIT成功找到了105个问题句子。我们用正确的翻译标记它们，并在15个时期内对这105个句子的NMT模型进行微调，并降低学习率。经过微调后，所有105个句子都可以正确翻译。同时，在训练过程中使用的原始验证集的BLEU得分增加了0.13，这在一定程度上表明其他句子的翻译也得到了改善。这证明了以有效且简便的方式修复SIT报告的错误的能力。 SIT用于构建强大的机器翻译软件的实用程序将在5.2节中进一步阐述。

## 讨论

### 关于误报

尽管SIT可以准确地检测翻译错误，但可以进一步提高其准确性。特别是，SIT的误报来自三个主要来源。首先，生成的句子可能具有奇怪的语义，从而导致目标句子结构发生变化。例如，基于短语“在路上”，SIT的当前实现可以生成句子“ on the fact”，该句子的中文翻译自然很不一样。使用BERT（在我们进行实验时提供了最新的屏蔽语言模型）有助于缓解此问题。其次，尽管现有的语法分析器非常准确，但是它们可能会产生错误的选区或依赖关系结构，这可能导致错误的报告错误。第三，源句可以具有不同句子结构的多种正确翻译。例如，目标句子“从现在开始十年”和“十年之后”可以在句子结构不同的情况下互换使用。为了降低这些因素的影响，SIT返回按与原始目标句子的距离排序的前k个可疑句子对。

### 构建鲁棒性强的翻译软件

与测试传统软件类似，测试机器翻译的最终目标是构建鲁棒的软件。为此，SIT的实用程序如下。首先，报告的错误翻译通常会作为早期警报，因此开发人员可以提前对翻译映射进行硬编码，这是业界采用的最快的错误修复解决方案。其次，报告的句子可以用作微调集，这已在4.7节中进行了讨论。第三，开发人员可能会发现所报告的错误句子对可用于进一步的分析/调试，因为每对句子之间仅相差一个单词。这类似于通过输入最小化/本地化调试传统软件。另外，结构不变性的概念可以用作归纳偏置来设计鲁棒的NMT模型，类似于Shen等人的方法。 [75]为标准LSTM引入了偏置项。与传统软件相比，机器翻译软件的调试和错误修复过程更加困难，因为NMT模型的逻辑主要在于其模型结构和参数。虽然这不是我们工作的重点，但我们认为这是未来工作的重要研究方向。

## 相关工作

### AI软件的健壮性

深度学习模型的成功导致人们在日常生活中广泛采用人工智能（AI）软件。尽管它们的准确性很高，但深度学习模型仍会产生较差的结果，其中一些结果甚至导致了致命的事故[42，45，100]。最近，研究人员设计了多种方法来攻击深度学习（DL）系统[3，6，7，20，29，89，91]。为了保护DL系统免受这些攻击，已经进行了出色的研究来测试DL系统[21、26、33、39、53、54、68、69、79、88、94、95]，以协助调试过程[ 55]，在线[56、77、84、90]检测对抗示例，或以健壮的方式[38、49、58、66]训练网络。与这些方法相比，我们的论文集中在机器翻译系统上，这些工作并未探讨。此外，这些方法大多数都需要了解被测神经网络中的梯度或激活值（白盒），而我们的方法不需要模型的任何内部细节（黑盒）。

### NLP算法的鲁棒性

深度神经网络提高了许多NLP任务的性能，例如阅读理解[9，10]，代码分析[1、35、70]和机器翻译[32、83、86]。 然而，近年来，受计算机视觉领域对抗性示例研究的启发，研究人员成功地发现了用于各种NLP系统的神经网络所产生的错误[2，8，36，36，37，46，61，62， 72]。 与我们的方法相比，这些作品集中于更简单的任务，例如文本分类。

郑等 [96]引入了两种算法来分别检测两个特定的翻译错误：翻译不足和翻译过度。 相比之下，我们提出的方法更加系统化，不仅限于特定的错误。 根据实验结果，我们可以发现以下错误：翻译不足，翻译过度，修饰不正确，多义性不明确以及逻辑不明确。 Zhou和Sun [97]提出了一种机器翻译的变形测试方法（即MT4MT）。 他们遵循类似于结构不变性的概念。 但是，MT4MT只能与主语-动词-宾语模式中的简单句子一起使用（例如，“汤姆喜欢耐克”）。 特别是，他们更改句子中的人名或品牌名称，并检查翻译是否相差一个以上。 因此，MT4MT无法报告大多数真实句子中的错误，例如本文中使用的数据集。 另外，MT4MT没有提出实现其思想的通用技术。

我们的工作通过非平凡的技术（例如，使BERT适应单词替换并利用语言解析器生成句子结构）引入了有效的实现，并进行了广泛的评估。

### 机器翻译

在过去的几年中，神经机器翻译（NMT）架构迅速发展[32，86]。 通常，NMT模型使用受关注的编码器-解码器框架[92]。 在此框架下，研究人员设计了各种先进的神经网络体系结构，范围从递归神经网络（RNN）[52、76]，卷积神经网络（CNN）[27、28]，到没有递归或卷积的全关注网络[83]。 。 这些现有论文旨在提高NMT模型的功能。 与它们不同的是，本文着重于NMT模型的鲁棒性。 我们认为，在实践中，鲁棒性与机器翻译的准确性一样重要。 因此，我们提出的方法可以补充现有的机器翻译研究。

### 变形测试

变形测试是一种基于现有测试案例生成测试案例的方法[12，13，73]。 关键思想是从具有不同输入的程序的多次运行中，跨输出检测出特定于领域的变形关系。 变形测试已用于测试各种传统软件，例如编译器[43，47]，科学库[93]和数据库系统[50]。 由于它对测试“不可测试”程序的有效性，研究人员还使用它来测试AI软件，例如统计分类器[63，87]，搜索引擎[98]和自动驾驶汽车[79，95]。 在本文中，我们介绍了用于机器翻译软件的结构不变测试，这是一种新颖的，可广泛应用的变形测试方法。

## 总结

我们介绍了结构不变测试（SIT），这是一种测试机器翻译软件的有效新方法。 SIT的独特优势在于它的简单性和通用性，因此具有广泛的适用性。 SIT已用于测试Google Translate和Bing Microsoft Translators，并成功地发现了64个和70个有问题的问题，其top-1准确性分别为69.5％和70％。 此外，作为一种通用方法，SIT可以发现最新方法无法发现的各种翻译错误。 我们认为这项工作是迈向机器翻译软件系统测试的重要的第一步。 为了将来的工作，我们将继续完善通用方法并将其扩展到其他AI软件（例如，图形字幕工具和面部识别系统）。 我们还将开展广泛的工作，以帮助不断测试和改进广泛使用的翻译系统。